{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VeriRegime - ONNXæ¨¡å‹å¯¼å‡º\n",
        "\n",
        "å°†è®­ç»ƒå¥½çš„MLP Studentå¯¼å‡ºä¸ºONNXæ ¼å¼ï¼Œç”¨äºzkMLè½¬æ¢\n",
        "\n",
        "**è¾“å…¥**ï¼š`results/checkpoints/best_student.pth`  \n",
        "**è¾“å‡º**ï¼š`results/onnx/student_model.onnx`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. å¯¼å…¥ä¾èµ–\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorchç‰ˆæœ¬: 2.9.1\n",
            "ONNXå¯¼å‡ºæ”¯æŒ: âœ…\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "import torch\n",
        "import torch.onnx\n",
        "import numpy as np\n",
        "import platform\n",
        "import os\n",
        "\n",
        "from train import MLPStudent\n",
        "\n",
        "print(f\"PyTorchç‰ˆæœ¬: {torch.__version__}\")\n",
        "print(f\"ONNXå¯¼å‡ºæ”¯æŒ: {'âœ…' if hasattr(torch.onnx, 'export') else 'âŒ'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. é…ç½®å‚æ•°\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "è¾“å…¥ç»´åº¦: 1680\n",
            "Checkpoint: ../results/checkpoints/best_student.pth\n",
            "ONNXè¾“å‡º: ../results/onnx/student_model.onnx\n"
          ]
        }
      ],
      "source": [
        "# æ¨¡å‹é…ç½®ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰\n",
        "FEATURE_COLS = ['ema_5', 'ema_10', 'ema_20', 'rsi', 'macd', 'volume_ma_5', 'volume_ma_10']\n",
        "SEQ_LENGTH = 240\n",
        "INPUT_DIM = SEQ_LENGTH * len(FEATURE_COLS)  # 1680\n",
        "\n",
        "# è·¯å¾„é…ç½®\n",
        "CHECKPOINT_PATH = '../results/checkpoints/best_student.pth'\n",
        "ONNX_DIR = '../results/onnx'\n",
        "ONNX_PATH = os.path.join(ONNX_DIR, 'student_model.onnx')\n",
        "\n",
        "# åˆ›å»ºè¾“å‡ºç›®å½•\n",
        "os.makedirs(ONNX_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"è¾“å…¥ç»´åº¦: {INPUT_DIM}\")\n",
        "print(f\"Checkpoint: {CHECKPOINT_PATH}\")\n",
        "print(f\"ONNXè¾“å‡º: {ONNX_PATH}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "åŠ è½½MLP Student...\n",
            "âœ… æ¨¡å‹åŠ è½½æˆåŠŸ\n",
            "  å‚æ•°é‡: 471,618\n",
            "  æœ€ä½³F1: 0.7256\n",
            "  è®­ç»ƒè½®æ¬¡: 25\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nåŠ è½½MLP Student...\")\n",
        "\n",
        "# åˆ›å»ºæ¨¡å‹\n",
        "model = MLPStudent(\n",
        "    input_dim=INPUT_DIM,\n",
        "    hidden_dims=[256, 128, 64],\n",
        "    dropout_rate=0.3\n",
        ")\n",
        "\n",
        "# åŠ è½½æƒé‡\n",
        "checkpoint = torch.load(CHECKPOINT_PATH, map_location='cpu')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()  # è®¾ä¸ºè¯„ä¼°æ¨¡å¼\n",
        "\n",
        "# ç»Ÿè®¡å‚æ•°\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "print(f\"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ\")\n",
        "print(f\"  å‚æ•°é‡: {total_params:,}\")\n",
        "print(f\"  æœ€ä½³F1: {checkpoint['best_f1']:.4f}\")\n",
        "print(f\"  è®­ç»ƒè½®æ¬¡: {checkpoint['epoch']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. å‡†å¤‡ç¤ºä¾‹è¾“å…¥\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "å‡†å¤‡ç¤ºä¾‹è¾“å…¥...\n",
            "è¾“å…¥å½¢çŠ¶: torch.Size([1, 240, 7])\n",
            "è¾“å…¥èŒƒå›´: [-3.44, 3.01]\n",
            "\n",
            "è¾“å‡ºlogits: [-1.2432619 -0.1276757]\n",
            "é¢„æµ‹ç±»åˆ«: 1 (HIGH Volatility)\n",
            "\n",
            "âœ… æ¨¡å‹æ¨ç†æ­£å¸¸\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nå‡†å¤‡ç¤ºä¾‹è¾“å…¥...\")\n",
        "\n",
        "# åˆ›å»ºç¤ºä¾‹è¾“å…¥ï¼ˆbatch_size=1ï¼Œseq_length=240ï¼Œfeatures=7ï¼‰\n",
        "dummy_input = torch.randn(1, SEQ_LENGTH, len(FEATURE_COLS))\n",
        "\n",
        "print(f\"è¾“å…¥å½¢çŠ¶: {dummy_input.shape}\")\n",
        "print(f\"è¾“å…¥èŒƒå›´: [{dummy_input.min():.2f}, {dummy_input.max():.2f}]\")\n",
        "\n",
        "# æµ‹è¯•æ¨¡å‹æ¨ç†\n",
        "with torch.no_grad():\n",
        "    output = model(dummy_input)\n",
        "    logits = output['logits']\n",
        "    pred = torch.argmax(logits, dim=1)\n",
        "\n",
        "print(f\"\\nè¾“å‡ºlogits: {logits[0].numpy()}\")\n",
        "print(f\"é¢„æµ‹ç±»åˆ«: {pred.item()} ({'HIGH' if pred.item() == 1 else 'LOW'} Volatility)\")\n",
        "print(f\"\\nâœ… æ¨¡å‹æ¨ç†æ­£å¸¸\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. å¯¼å‡ºONNXæ¨¡å‹\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/20/z7rcn5zx7hbcd8xbwb89m51h0000gn/T/ipykernel_49863/3896541333.py:15: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
            "  torch.onnx.export(\n",
            "W1202 10:41:56.012000 49863 site-packages/torch/onnx/_internal/exporter/_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 14 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "å¼€å§‹å¯¼å‡ºONNX...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 14).\n",
            "Failed to convert the model to the target version 14 using the ONNX C API. The model was not modified\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/lambertlin/anaconda3/envs/ml/lib/python3.12/site-packages/onnxscript/version_converter/__init__.py\", line 127, in call\n",
            "    converted_proto = _c_api_utils.call_onnx_api(\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/lambertlin/anaconda3/envs/ml/lib/python3.12/site-packages/onnxscript/version_converter/_c_api_utils.py\", line 65, in call_onnx_api\n",
            "    result = func(proto)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/Users/lambertlin/anaconda3/envs/ml/lib/python3.12/site-packages/onnxscript/version_converter/__init__.py\", line 122, in _partial_convert_version\n",
            "    return onnx.version_converter.convert_version(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/lambertlin/anaconda3/envs/ml/lib/python3.12/site-packages/onnx/version_converter.py\", line 39, in convert_version\n",
            "    converted_model_str = C.convert_version(model_str, target_version)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: /Users/runner/work/onnx/onnx/onnx/version_converter/BaseConverter.h:68: adapter_lookup: Assertion `false` failed: No Adapter From Version $16 for Identity\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applied 1 of general pattern rewrite rules.\n",
            "âœ… ONNXå¯¼å‡ºæˆåŠŸ: ../results/onnx/student_model.onnx\n",
            "  æ–‡ä»¶å¤§å°: 13.32 KB\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nå¼€å§‹å¯¼å‡ºONNX...\")\n",
        "\n",
        "# ONNXå¯¼å‡ºé…ç½®ï¼ˆä½¿ç”¨PyTorch 2.9æœ€ä½³å®è·µï¼‰\n",
        "input_names = ['input']\n",
        "output_names = ['logits', 'features']\n",
        "\n",
        "# ä½¿ç”¨dynamic_shapesæ›¿ä»£dynamic_axesï¼ˆé¿å…è­¦å‘Šï¼‰\n",
        "from torch.export import Dim\n",
        "batch_dim = Dim(\"batch\", min=1, max=1024)\n",
        "\n",
        "dynamic_shapes = {\n",
        "    \"input\": {0: batch_dim}\n",
        "}\n",
        "\n",
        "# å¯¼å‡ºONNXï¼ˆä½¿ç”¨Opset 18ï¼ŒEZKLå®Œå…¨å…¼å®¹ï¼‰\n",
        "torch.onnx.export(\n",
        "    model,\n",
        "    dummy_input,\n",
        "    ONNX_PATH,\n",
        "    export_params=True,\n",
        "    opset_version=18,  # ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬ï¼ˆEZKLæ”¯æŒ12-18ï¼‰\n",
        "    do_constant_folding=True,\n",
        "    input_names=input_names,\n",
        "    output_names=output_names,\n",
        "    dynamic_shapes=dynamic_shapes,  # æ–°APIï¼Œé¿å…è­¦å‘Š\n",
        "    dynamo=True,  # æ˜¾å¼å¯ç”¨æ–°å¯¼å‡ºå™¨\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "print(f\"âœ… ONNXå¯¼å‡ºæˆåŠŸ: {ONNX_PATH}\")\n",
        "print(f\"  ä½¿ç”¨Opset 18ï¼ˆæœ€æ–°ï¼Œæ— è­¦å‘Šï¼‰\")\n",
        "print(f\"  åŠ¨æ€batch_sizeæ”¯æŒ: 1-1024\")\n",
        "\n",
        "# æ£€æŸ¥æ–‡ä»¶å¤§å°\n",
        "file_size = os.path.getsize(ONNX_PATH) / 1024  # KB\n",
        "print(f\"  æ–‡ä»¶å¤§å°: {file_size:.2f} KB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. éªŒè¯ONNXæ¨¡å‹\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "éªŒè¯ONNXæ¨¡å‹...\n",
            "âœ… ONNXæ¨¡å‹æ ¼å¼æœ‰æ•ˆ\n",
            "\n",
            "æ¨¡å‹ä¿¡æ¯:\n",
            "  IRç‰ˆæœ¬: 10\n",
            "  Opsetç‰ˆæœ¬: 18\n",
            "  ç”Ÿäº§è€…: pytorch\n",
            "\n",
            "è¾“å…¥:\n",
            "  input: ['dynamic', 240, 7]\n",
            "\n",
            "è¾“å‡º:\n",
            "  logits: ['dynamic', 2]\n"
          ]
        }
      ],
      "source": [
        "print(\"\\néªŒè¯ONNXæ¨¡å‹...\")\n",
        "\n",
        "import onnx\n",
        "import onnxruntime as ort\n",
        "\n",
        "# åŠ è½½ONNXæ¨¡å‹\n",
        "onnx_model = onnx.load(ONNX_PATH)\n",
        "\n",
        "# æ£€æŸ¥æ¨¡å‹æœ‰æ•ˆæ€§\n",
        "try:\n",
        "    onnx.checker.check_model(onnx_model)\n",
        "    print(\"âœ… ONNXæ¨¡å‹æ ¼å¼æœ‰æ•ˆ\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ ONNXæ¨¡å‹æ£€æŸ¥å¤±è´¥: {e}\")\n",
        "    raise\n",
        "\n",
        "# æ‰“å°æ¨¡å‹ä¿¡æ¯\n",
        "print(f\"\\næ¨¡å‹ä¿¡æ¯:\")\n",
        "print(f\"  IRç‰ˆæœ¬: {onnx_model.ir_version}\")\n",
        "print(f\"  Opsetç‰ˆæœ¬: {onnx_model.opset_import[0].version}\")\n",
        "print(f\"  ç”Ÿäº§è€…: {onnx_model.producer_name}\")\n",
        "\n",
        "print(f\"\\nè¾“å…¥:\")\n",
        "for input_tensor in onnx_model.graph.input:\n",
        "    shape = [d.dim_value if d.dim_value > 0 else 'dynamic' for d in input_tensor.type.tensor_type.shape.dim]\n",
        "    print(f\"  {input_tensor.name}: {shape}\")\n",
        "\n",
        "print(f\"\\nè¾“å‡º:\")\n",
        "for output_tensor in onnx_model.graph.output:\n",
        "    shape = [d.dim_value if d.dim_value > 0 else 'dynamic' for d in output_tensor.type.tensor_type.shape.dim]\n",
        "    print(f\"  {output_tensor.name}: {shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. ONNX Runtimeæ¨ç†æµ‹è¯•\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ONNX Runtimeæ¨ç†æµ‹è¯•...\n",
            "ONNXè¾“å‡ºlogits: [-1.243262   -0.12767568]\n",
            "ONNXé¢„æµ‹ç±»åˆ«: 1\n",
            "\n",
            "PyTorch vs ONNXæœ€å¤§å·®å¼‚: 0.000000\n",
            "âœ… ONNXæ¨¡å‹ä¸PyTorchæ¨¡å‹ä¸€è‡´ï¼ˆå·®å¼‚ < 1e-5ï¼‰\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nONNX Runtimeæ¨ç†æµ‹è¯•...\")\n",
        "\n",
        "# åˆ›å»ºONNX Runtimeä¼šè¯\n",
        "ort_session = ort.InferenceSession(ONNX_PATH)\n",
        "\n",
        "# å‡†å¤‡è¾“å…¥\n",
        "ort_inputs = {ort_session.get_inputs()[0].name: dummy_input.numpy()}\n",
        "\n",
        "# è¿è¡Œæ¨ç†\n",
        "ort_outputs = ort_session.run(None, ort_inputs)\n",
        "ort_logits = ort_outputs[0]\n",
        "\n",
        "print(f\"ONNXè¾“å‡ºlogits: {ort_logits[0]}\")\n",
        "print(f\"ONNXé¢„æµ‹ç±»åˆ«: {np.argmax(ort_logits[0])}\")\n",
        "\n",
        "# å¯¹æ¯”PyTorchå’ŒONNXè¾“å‡º\n",
        "with torch.no_grad():\n",
        "    pytorch_output = model(dummy_input)['logits'].numpy()\n",
        "\n",
        "diff = np.abs(pytorch_output - ort_logits).max()\n",
        "print(f\"\\nPyTorch vs ONNXæœ€å¤§å·®å¼‚: {diff:.6f}\")\n",
        "\n",
        "if diff < 1e-5:\n",
        "    print(\"âœ… ONNXæ¨¡å‹ä¸PyTorchæ¨¡å‹ä¸€è‡´ï¼ˆå·®å¼‚ < 1e-5ï¼‰\")\n",
        "elif diff < 1e-3:\n",
        "    print(\"âš ï¸ ONNXæ¨¡å‹ä¸PyTorchæœ‰è½»å¾®å·®å¼‚ï¼ˆ1e-5 < å·®å¼‚ < 1e-3ï¼‰\")\n",
        "else:\n",
        "    print(f\"âŒ ONNXæ¨¡å‹ä¸PyTorchå·®å¼‚è¾ƒå¤§ï¼ˆå·®å¼‚ = {diff:.6f}ï¼‰\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. ä¿å­˜æ¨¡å‹å…ƒæ•°æ®\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ… å…ƒæ•°æ®å·²ä¿å­˜: ../results/onnx/model_metadata.json\n",
            "\n",
            "============================================================\n",
            "ğŸ‰ ONNXå¯¼å‡ºå®Œæˆï¼\n",
            "============================================================\n",
            "\n",
            "ä¸‹ä¸€æ­¥: ä½¿ç”¨EZKLè¿›è¡ŒzkMLè½¬æ¢\n",
            "  1. å®‰è£…EZKL: scripts/setup_ezkl.sh\n",
            "  2. è¿è¡Œè½¬æ¢: notebooks/zkml_pipeline.ipynb\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "metadata = {\n",
        "    'export_time': datetime.now().isoformat(),\n",
        "    'model': {\n",
        "        'type': 'MLPStudent',\n",
        "        'input_dim': INPUT_DIM,\n",
        "        'hidden_dims': [256, 128, 64],\n",
        "        'output_dim': 2,\n",
        "        'total_params': total_params,\n",
        "        'dropout_rate': 0.3\n",
        "    },\n",
        "    'training': {\n",
        "        'best_f1': float(checkpoint['best_f1']),\n",
        "        'epoch': checkpoint['epoch']\n",
        "    },\n",
        "    'onnx': {\n",
        "        'path': ONNX_PATH,\n",
        "        'opset_version': 18,  # å®é™…ä½¿ç”¨çš„ç‰ˆæœ¬\n",
        "        'file_size_kb': file_size,\n",
        "        'input_shape': [1, SEQ_LENGTH, len(FEATURE_COLS)],\n",
        "        'output_shape': [1, 2],\n",
        "        'dynamic_batch': True  # æ”¯æŒåŠ¨æ€batch_size\n",
        "    },\n",
        "    'features': FEATURE_COLS,\n",
        "    'seq_length': SEQ_LENGTH\n",
        "}\n",
        "\n",
        "metadata_path = os.path.join(ONNX_DIR, 'model_metadata.json')\n",
        "with open(metadata_path, 'w') as f:\n",
        "    json.dump(metadata, f, indent=2)\n",
        "\n",
        "print(f\"\\nâœ… å…ƒæ•°æ®å·²ä¿å­˜: {metadata_path}\")\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"ğŸ‰ ONNXå¯¼å‡ºå®Œæˆï¼\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"\\nä¸‹ä¸€æ­¥: ä½¿ç”¨EZKLè¿›è¡ŒzkMLè½¬æ¢\")\n",
        "print(f\"  1. å®‰è£…EZKL: scripts/setup_ezkl.sh\")\n",
        "print(f\"  2. è¿è¡Œè½¬æ¢: notebooks/zkml_pipeline.ipynb\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
