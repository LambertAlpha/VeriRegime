\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algpseudocode}

\title{\textbf{VeriRegime: Distilling High-Performance CNNs to zkML-Optimized MLPs for Trading Signal Generation}\\
\vspace{0.3cm}
\large DDA4220 Deep Learning - Midterm Report}

\author{Lambert Lin}
\date{November 8, 2024}

\begin{document}

\maketitle

\section{Introduction}

\subsection{Topic and Motivation}

Zero-knowledge machine learning (zkML) enables cryptographic verification of neural network inference on blockchain systems, providing trustless and transparent AI decision-making. However, current zkML implementations face significant practical challenges:

\begin{itemize}
    \item \textbf{Computational Overhead}: Complex architectures like CNNs and LSTMs require 100--2000 seconds for proof generation, making real-time applications infeasible.
    \item \textbf{Architecture Constraints}: zkML-friendly operations (e.g., polynomial activations, integer arithmetic) severely limit model expressiveness.
    \item \textbf{Accuracy-Efficiency Trade-off}: Naive simplification of architectures (e.g., direct training of shallow MLPs) often results in 20--40\% accuracy degradation.
\end{itemize}

\textbf{Research Question}: Can we systematically transfer knowledge from high-performance but zkML-unfriendly models (CNNs) to efficient and verifiable models (MLPs) while maintaining competitive accuracy?

Our project proposes a \textbf{knowledge distillation framework} that transforms trained CNN models into compact MLPs optimized for zkML deployment. We use cryptocurrency trading signal generation as a testbed, where:
\begin{itemize}
    \item Time-series financial data provides a realistic benchmark.
    \item On-chain verifiable trading signals demonstrate practical zkML utility.
    \item Performance metrics (accuracy, F1 score) are directly interpretable.
\end{itemize}

\subsection{Research Contributions}

\begin{enumerate}
    \item \textbf{CNN�MLP Distillation Framework}: Theoretical and empirical analysis of why CNN temporal features can be learned by position-aware MLPs.
    \item \textbf{zkML Optimization Pipeline}: Combining polynomial activation replacement and Hessian-guided adaptive quantization.
    \item \textbf{Comprehensive Benchmarking}: End-to-end evaluation of accuracy retention vs. proof generation speedup using the EZKL framework.
\end{enumerate}

\section{Related Work}

\subsection{Knowledge Distillation}

\textbf{Hinton et al. (2015) - Distilling the Knowledge in a Neural Network}~\cite{hinton2015distilling}

The seminal work introduced the concept of ``dark knowledge'' --- soft probability distributions from teacher models that contain richer information than hard labels. Key insights:
\begin{itemize}
    \item Temperature-scaled softmax ($\sigma_T(z) = \frac{\exp(z_i/T)}{\sum_j \exp(z_j/T)}$) reveals inter-class similarities.
    \item Combined loss: $\mathcal{L} = \alpha \mathcal{L}_{\text{CE}}(y, \hat{y}) + \beta \mathcal{L}_{\text{KL}}(p_T, q_T)$.
    \item Achieves 85--92\% teacher accuracy on MNIST/CIFAR-10.
\end{itemize}

\textbf{Urban et al. (2017) - Do Deep Convolutional Nets Really Need to be Deep?}~\cite{urban2017deep}

Demonstrated that shallow MLPs can mimic deep CNN behavior through distillation:
\begin{itemize}
    \item Experimented with VGG-16 � MLP (CIFAR-10, ImageNet).
    \item Achieved 87\% accuracy retention with 10� parameter reduction.
    \item Revealed that CNNs learn compositional features, but final representations are often linearly separable.
\end{itemize}

\textbf{Implications for Our Work}:
\begin{itemize}
    \item CNNs extract local temporal patterns (via convolution), which can be approximated by fully-connected layers given sufficient capacity.
    \item For 1D time-series, position-dependent weights in MLPs can replicate convolutional feature maps.
\end{itemize}

\subsection{Zero-Knowledge Machine Learning}

\textbf{EZKL (Kang et al., 2023) - ZKML: An Optimizing System for ML Inference in Zero-Knowledge}~\cite{ezkl2023}

EZKL compiles ONNX models to arithmetic circuits compatible with Halo2 proof systems:
\begin{itemize}
    \item Supports operations: polynomial activations, matrix multiplication, quantization.
    \item Constraint complexity: $C \approx 2^{15}$ to $2^{20}$ constraints for typical models.
    \item Proving time: $T \propto C \cdot \log C$ (empirically 10--500 seconds).
\end{itemize}

\textbf{Optimizations in Prior Work}:
\begin{itemize}
    \item \textbf{Activation Replacement}: Replacing ReLU with $x^2$, $x - x^3/6$ reduces constraints by 30--50\%.
    \item \textbf{Quantization}: Lower bit-width (4--8 bits) reduces field arithmetic operations by 40--60\%.
    \item \textbf{Model Simplification}: Pruning, layer fusion, and architecture search.
\end{itemize}

\textbf{Gaps Our Work Addresses}:
\begin{itemize}
    \item Existing work focuses on \textit{system-level} optimization (compiler tricks, hardware acceleration).
    \item We propose \textit{model-level} optimization via distillation to inherently simpler architectures.
\end{itemize}

\subsection{Financial Time-Series Prediction}

Reviewed baseline approaches for trading signal generation:
\begin{itemize}
    \item Technical indicators (EMA, RSI, MACD) as hand-crafted features.
    \item CNN/LSTM for temporal pattern extraction (accuracy: 55--65\% on cryptocurrency data).
    \item Threshold-based labeling strategies (e.g., $\pm 0.2\%$ price change for BUY/HOLD/SELL).
\end{itemize}

\section{Methodology}

\subsection{Problem Formulation}

\textbf{Input}: Time-series window $\mathbf{X} \in \mathbb{R}^{T \times d}$ ($T=60$ minutes, $d=7$ features).

\textbf{Features}: EMA(5,10,20), RSI(14), MACD, VolumeMA(5,10).

\textbf{Output}: Trading signal $y \in \{0, 1, 2\}$ (SELL, HOLD, BUY).

\textbf{Labeling}: Based on 1-hour forward return:
\[
r = \frac{p_{t+60} - p_t}{p_t} \times 100\%
\]
\[
y = \begin{cases}
2 & \text{if } r > 0.2\% \quad (\text{BUY}) \\
1 & \text{if } -0.2\% \leq r \leq 0.2\% \quad (\text{HOLD}) \\
0 & \text{if } r < -0.2\% \quad (\text{SELL})
\end{cases}
\]

\subsection{CNN Teacher Architecture}

\begin{algorithm}
\caption{CNN Teacher Forward Pass}
\begin{algorithmic}[1]
\State \textbf{Input}: $\mathbf{X} \in \mathbb{R}^{B \times T \times d}$ (batch, time, features)
\State $\mathbf{X} \gets \text{Permute}(\mathbf{X})$ \Comment{$(B, T, d) \to (B, d, T)$}
\State $\mathbf{H}_1 \gets \text{ReLU}(\text{BN}(\text{Conv1D}_{64}^{k=5}(\mathbf{X})))$
\State $\mathbf{H}_1 \gets \text{MaxPool}_2(\mathbf{H}_1)$ \Comment{$T=60 \to 30$}
\State $\mathbf{H}_2 \gets \text{ReLU}(\text{BN}(\text{Conv1D}_{128}^{k=3}(\mathbf{H}_1)))$
\State $\mathbf{H}_2 \gets \text{MaxPool}_2(\mathbf{H}_2)$ \Comment{$T=30 \to 15$}
\State $\mathbf{Z} \gets \text{GlobalAvgPool}(\mathbf{H}_2)$ \Comment{$(B, 128, 15) \to (B, 128)$}
\State $\mathbf{Y} \gets \text{Softmax}(\text{FC}_{3}(\mathbf{Z}))$
\State \textbf{Return} $\mathbf{Y}$
\end{algorithmic}
\end{algorithm}

\textbf{Parameters}: 27,779 (lightweight for zkML baseline comparison).

\subsection{MLP Student Architecture (Planned)}

\textbf{Input Flattening}: $\mathbf{X}_{\text{flat}} = \text{Flatten}(\mathbf{X}) \in \mathbb{R}^{480}$

\textbf{Architecture}:
\[
\mathbf{X}_{\text{flat}} \xrightarrow{\text{FC}_{128}} \mathbf{H}_1 \xrightarrow{\sigma_{\text{poly}}} \mathbf{H}_1' \xrightarrow{\text{FC}_{64}} \mathbf{H}_2 \xrightarrow{\sigma_{\text{poly}}} \mathbf{H}_2' \xrightarrow{\text{FC}_{32}} \mathbf{H}_3 \xrightarrow{\sigma_{\text{poly}}} \mathbf{H}_3' \xrightarrow{\text{FC}_3} \mathbf{Y}
\]

\textbf{Parameters}: $\sim$80K (similar capacity to CNN but zkML-friendly).

\subsection{Knowledge Distillation Loss}

\[
\mathcal{L}_{\text{total}} = \alpha \cdot \mathcal{L}_{\text{CE}}(y, \hat{y}_{\text{student}}) + \beta \cdot \mathcal{L}_{\text{KD}}(z_{\text{teacher}}, z_{\text{student}}) + \gamma \cdot \mathcal{L}_{\text{reg}}
\]

Where:
\begin{itemize}
    \item $\mathcal{L}_{\text{CE}}$: Cross-entropy with ground truth labels.
    \item $\mathcal{L}_{\text{KD}} = \text{KL}(\sigma_T(z_{\text{teacher}}) \| \sigma_T(z_{\text{student}}))$: Distillation loss with temperature $T$.
    \item $\mathcal{L}_{\text{reg}} = \lambda_1 \|\mathbf{W}\|_1 + \lambda_2 \sum_i \text{ReLU}(|w_i| - \tau)$: Sparsity regularization.
\end{itemize}

\textbf{Hyperparameters to Tune}: $\alpha, \beta, T, \lambda_1, \lambda_2, \tau$.

\section{Experimental Plan}

\subsection{Metrics}

\begin{table}[h]
\centering
\begin{tabular}{llp{7cm}}
\toprule
\textbf{Metric} & \textbf{Symbol} & \textbf{Definition} \\
\midrule
Accuracy & $A$ & $\frac{\text{Correct Predictions}}{\text{Total Samples}}$ \\
F1 Score & $F_1$ & $\frac{2 \cdot \text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}$ \\
Retention Rate & $\rho$ & $\frac{A_{\text{student}}}{A_{\text{teacher}}} \times 100\%$ \\
Constraint Count & $C$ & Number of arithmetic constraints in zkML circuit \\
Proving Time & $T_{\text{prove}}$ & Time to generate zero-knowledge proof (seconds) \\
Verification Time & $T_{\text{verify}}$ & Time to verify proof (milliseconds) \\
Speedup & $S$ & $\frac{T_{\text{prove}}^{\text{CNN}}}{T_{\text{prove}}^{\text{MLP}}}$ \\
\bottomrule
\end{tabular}
\caption{Evaluation Metrics}
\end{table}

\subsection{Planned Experiments}

\begin{table}[h]
\centering
\begin{tabular}{clp{5cm}l}
\toprule
\textbf{\#} & \textbf{Experiment} & \textbf{Goal} & \textbf{Week} \\
\midrule
0 & CNN Teacher Baseline & Establish performance upper bound & Week 7 \\
1 & CNN�MLP Distillation & Validate knowledge transfer & Week 8 \\
2 & Polynomial Activation & Reduce constraints while maintaining accuracy & Week 9 \\
3 & Adaptive Quantization & Further constraint reduction via Hessian-guided bit-width allocation & Week 9 \\
4 & EZKL Compilation & Measure end-to-end zkML performance & Week 10 \\
\bottomrule
\end{tabular}
\caption{Experiment Roadmap}
\end{table}

\textbf{Success Criteria}:
\begin{itemize}
    \item \textbf{Minimum}: $\rho \geq 80\%$, $S \geq 5\times$
    \item \textbf{Expected}: $\rho \geq 85\%$, $S \geq 10\times$, Accuracy drop $< 5\%$
    \item \textbf{Ideal}: $\rho \geq 90\%$, $S \geq 20\times$, Accuracy drop $< 3\%$
\end{itemize}

\section{Progress and Results}

\subsection{Dataset Construction}

\textbf{Data Source}: Binance API (BTC/USDT 1-minute candlesticks)

\textbf{Time Range}: 2022-12-31 to 2024-11-07 (685 days)

\textbf{Total Samples}: 974,907 (after removing NaN from indicator calculations)

\textbf{Data Split}:
\begin{itemize}
    \item \textbf{Training}: 682,434 samples (70\%) --- 2022-12-31 to 2024-04-18
    \item \textbf{Validation}: 146,236 samples (15\%) --- 2024-04-18 to 2024-07-29
    \item \textbf{Test}: 146,237 samples (15\%) --- 2024-07-29 to 2024-11-07
\end{itemize}

\textbf{Label Distribution} (after threshold optimization):
\begin{table}[h]
\centering
\begin{tabular}{lrrr}
\toprule
\textbf{Label} & \textbf{Training} & \textbf{Validation} & \textbf{Test} \\
\midrule
SELL (0) & 146,917 (21.5\%) & 36,654 (25.1\%) & 39,328 (26.9\%) \\
HOLD (1) & 374,820 (54.9\%) & 70,959 (48.5\%) & 66,233 (45.3\%) \\
BUY (2) & 160,637 (23.5\%) & 38,563 (26.4\%) & 40,616 (27.8\%) \\
\bottomrule
\end{tabular}
\caption{Label Distribution Across Splits}
\end{table}

\textbf{Key Challenge Addressed}: Initial labeling with $\pm 2\%$ threshold resulted in 99\% HOLD labels (severe class imbalance). We systematically analyzed return distributions and optimized the threshold to $\pm 0.2\%$, achieving a more balanced distribution (23\% / 53\% / 24\%).

\subsection{CNN Teacher Training (Experiment 0 - In Progress)}

\textbf{Training Configuration}:
\begin{itemize}
    \item Optimizer: AdamW (lr=1e-3, weight\_decay=1e-4)
    \item Batch Size: 256
    \item Epochs: 50 (with early stopping, patience=10)
    \item Loss: CrossEntropy + Label Smoothing (0.1)
    \item Learning Rate Scheduler: ReduceLROnPlateau (factor=0.5, patience=5)
\end{itemize}

\textbf{Current Status} (as of Epoch 2/50):
\begin{itemize}
    \item \textbf{Epoch 1 Results}:
    \begin{itemize}
        \item Train Loss: 0.9627, Train Acc: 56.40\%
        \item Val Loss: 1.0318, Val Acc: 50.54\%
        \item \textbf{Val F1: 0.3875}
    \end{itemize}
    \item \textbf{Epoch 2} (ongoing): Train Acc trending around 57\%
\end{itemize}

\textbf{Preliminary Analysis}:
\begin{itemize}
    \item Validation accuracy (50.54\%) is only marginally better than random (33.33\% for 3-class problem).
    \item Low F1 score (0.3875) suggests the model struggles with minority classes (SELL/BUY).
    \item Possible causes:
    \begin{enumerate}
        \item \textbf{Class Imbalance}: Despite threshold optimization, HOLD still dominates (53\%).
        \item \textbf{Feature Quality}: Technical indicators may not be sufficiently predictive for 1-hour forward returns.
        \item \textbf{Model Capacity}: Current CNN (27K params) may be too small.
        \item \textbf{Task Difficulty}: Cryptocurrency price movements are inherently noisy and difficult to predict.
    \end{enumerate}
\end{itemize}

\subsection{Implementation Details}

\textbf{Code Repository Structure}:
\begin{verbatim}
VeriRegime/
   src/
      data_collection.py      # Binance API data fetching
      data_split.py            # Train/val/test splitting
      relabel_data.py          # Label threshold optimization
      train_cnn.py             # CNN training script
      models/
         cnn_teacher.py       # CNN architecture
      data/
          dataset.py           # PyTorch Dataset (sliding window)
   data/
      btc_usdt_1m_processed.csv
      train.csv, val.csv, test.csv
   models/                      # Saved model checkpoints
   results/                     # Training logs and visualizations
\end{verbatim}

\textbf{Technical Stack}:
\begin{itemize}
    \item PyTorch 2.9.0
    \item CCXT (Binance API)
    \item pandas-ta (technical indicators)
    \item scikit-learn (metrics)
\end{itemize}

\section{Challenges and Next Steps}

\subsection{Current Challenges}

\begin{enumerate}
    \item \textbf{Low CNN Baseline Performance}:
    \begin{itemize}
        \item Current validation accuracy (50.54\%) is below our target (60\%+).
        \item This limits the upper bound for distillation experiments.
    \end{itemize}

    \item \textbf{Class Imbalance}:
    \begin{itemize}
        \item HOLD class dominates, leading to biased predictions.
        \item F1 score (0.3875) indicates poor performance on minority classes.
    \end{itemize}

    \item \textbf{Feature Engineering}:
    \begin{itemize}
        \item Current 7 technical indicators may be insufficient.
        \item Need to explore additional features (e.g., order book depth, funding rates, volatility metrics).
    \end{itemize}
\end{enumerate}

\subsection{Planned Improvements}

\textbf{Short-Term (Week 7-8)}:
\begin{enumerate}
    \item \textbf{Address Class Imbalance}:
    \begin{itemize}
        \item Implement class weights in loss function: $\mathcal{L}_{\text{CE}} = -\sum_{i} w_i y_i \log(\hat{y}_i)$
        \item Try focal loss: $\mathcal{L}_{\text{focal}} = -\alpha (1-\hat{y})^\gamma \log(\hat{y})$
        \item Oversample minority classes (SMOTE or simple duplication)
    \end{itemize}

    \item \textbf{Increase Model Capacity}:
    \begin{itemize}
        \item Add a third convolutional layer (128 � 256 filters)
        \item Increase FC layer width (128 � 256)
        \item Target: 50--100K parameters (still reasonable for zkML baseline)
    \end{itemize}

    \item \textbf{Improve Training Strategy}:
    \begin{itemize}
        \item Longer training (100 epochs instead of 50)
        \item Cosine annealing LR schedule
        \item Gradient clipping to stabilize training
    \end{itemize}
\end{enumerate}

\textbf{Medium-Term (Week 8-9)}:
\begin{enumerate}
    \item \textbf{Feature Engineering}:
    \begin{itemize}
        \item Add Bollinger Bands, ATR (Average True Range)
        \item Include price momentum features (rate of change)
        \item Normalize features more carefully (z-score normalization)
    \end{itemize}

    \item \textbf{Hyperparameter Tuning}:
    \begin{itemize}
        \item Grid search over learning rates $\{1\mathrm{e}{-4}, 5\mathrm{e}{-4}, 1\mathrm{e}{-3}\}$
        \item Experiment with batch sizes $\{128, 256, 512\}$
        \item Tune label smoothing $\{0, 0.05, 0.1, 0.2\}$
    \end{itemize}
\end{enumerate}

\subsection{Contingency Plans}

\textbf{If CNN baseline remains below 60\% after improvements}:
\begin{itemize}
    \item \textbf{Option 1}: Accept lower baseline and focus on demonstrating \textit{relative} distillation success (e.g., 85\% retention of 55\% = 46.75\% absolute accuracy).
    \item \textbf{Option 2}: Simplify the task:
    \begin{itemize}
        \item Binary classification (BUY/SELL, remove HOLD).
        \item Predict direction only (up/down) instead of magnitude.
    \end{itemize}
    \item \textbf{Option 3}: Change dataset to a more predictable time-series (e.g., stock market with less volatility, or synthetic data).
\end{itemize}

\subsection{Timeline Adjustments}

\begin{table}[h]
\centering
\begin{tabular}{llp{6cm}}
\toprule
\textbf{Week} & \textbf{Status} & \textbf{Tasks} \\
\midrule
Week 7 & \textcolor{orange}{Ongoing} & CNN baseline training + debugging \\
Week 8 & \textcolor{blue}{Planned} & MLP Student + Distillation (Exp 1) \\
Week 9 & \textcolor{blue}{Planned} & Polynomial Activation (Exp 2) + Quantization (Exp 3) \\
Week 10 & \textcolor{blue}{Planned} & EZKL Compilation (Exp 4) \\
Week 11--12 & \textcolor{blue}{Planned} & Analysis, Pareto optimization, report writing \\
Week 13 & \textcolor{blue}{Planned} & Final report submission \\
\bottomrule
\end{tabular}
\caption{Updated Timeline}
\end{table}

\section{Conclusion}

This midterm report documents the progress of the VeriRegime project, which aims to optimize neural networks for zero-knowledge machine learning through knowledge distillation. We have:

\begin{itemize}
    \item Established a solid theoretical foundation by reviewing distillation and zkML literature.
    \item Collected and preprocessed a large-scale financial time-series dataset (975K samples).
    \item Implemented and begun training a CNN Teacher baseline model.
\end{itemize}

\textbf{Key Findings So Far}:
\begin{enumerate}
    \item Label threshold optimization is critical for balanced classification in financial data.
    \item Initial CNN performance (50.54\% validation accuracy) is below target, indicating room for improvement.
    \item The project is technically feasible but requires iterative refinement.
\end{enumerate}

\textbf{Next Steps}:
\begin{enumerate}
    \item Address class imbalance through weighted loss functions.
    \item Increase model capacity and training duration.
    \item Proceed with distillation experiments once a satisfactory baseline is achieved.
\end{enumerate}

We remain confident that the proposed distillation framework will demonstrate meaningful improvements in zkML efficiency while maintaining competitive accuracy for trading signal generation.

\begin{thebibliography}{9}

\bibitem{hinton2015distilling}
Hinton, G., Vinyals, O., \& Dean, J. (2015).
\textit{Distilling the knowledge in a neural network}.
arXiv preprint arXiv:1503.02531.

\bibitem{urban2017deep}
Urban, G., Geras, K. J., Kahou, S. E., Aslan, O., Wang, S., Caruana, R., ... \& Bengio, Y. (2017).
\textit{Do deep convolutional nets really need to be deep and convolutional?}.
ICLR 2017.

\bibitem{ezkl2023}
Kang, D., Hashimoto, T., Stoica, I., \& Sun, Y. (2023).
\textit{ZKML: An optimizing system for ML inference in zero-knowledge}.
Cryptology ePrint Archive.

\bibitem{dong2019hawq}
Dong, Z., Yao, Z., Gholami, A., Mahoney, M. W., \& Keutzer, K. (2019).
\textit{HAWQ: Hessian aware quantization of neural networks with mixed-precision}.
ICCV 2019.

\bibitem{gholami2021survey}
Gholami, A., Kim, S., Dong, Z., Yao, Z., Mahoney, M. W., \& Keutzer, K. (2021).
\textit{A survey of quantization methods for efficient neural network inference}.
arXiv preprint arXiv:2103.13630.

\end{thebibliography}

\end{document}
