"""
æ•°æ®åˆ†å‰²è„šæœ¬ï¼šæŒ‰æ—¶é—´é¡ºåºåˆ†å‰²è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†
é¿å…æ—¶é—´æ³„æ¼ï¼Œç¡®ä¿è®­ç»ƒæ•°æ®åœ¨éªŒè¯/æµ‹è¯•æ•°æ®ä¹‹å‰
"""

import pandas as pd
import numpy as np
from pathlib import Path

def split_time_series_data(input_file, output_dir='data',
                           train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):
    """
    æŒ‰æ—¶é—´é¡ºåºåˆ†å‰²æ—¶é—´åºåˆ—æ•°æ®

    Args:
        input_file: å¤„ç†åçš„æ•°æ®æ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        train_ratio: è®­ç»ƒé›†æ¯”ä¾‹
        val_ratio: éªŒè¯é›†æ¯”ä¾‹
        test_ratio: æµ‹è¯•é›†æ¯”ä¾‹

    Returns:
        train_df, val_df, test_df
    """
    # éªŒè¯æ¯”ä¾‹
    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, \
        "æ¯”ä¾‹ä¹‹å’Œå¿…é¡»ä¸º1.0"

    print(f"è¯»å–æ•°æ®æ–‡ä»¶: {input_file}")
    df = pd.read_csv(input_file, index_col=0, parse_dates=True)

    total_samples = len(df)
    print(f"æ€»æ ·æœ¬æ•°: {total_samples:,}")
    print(f"æ—¶é—´èŒƒå›´: {df.index[0]} è‡³ {df.index[-1]}")
    print(f"ç‰¹å¾åˆ—: {list(df.columns)}")

    # è®¡ç®—åˆ†å‰²ç‚¹ï¼ˆæŒ‰æ—¶é—´é¡ºåºï¼‰
    train_end_idx = int(total_samples * train_ratio)
    val_end_idx = int(total_samples * (train_ratio + val_ratio))

    # åˆ†å‰²æ•°æ®
    train_df = df.iloc[:train_end_idx]
    val_df = df.iloc[train_end_idx:val_end_idx]
    test_df = df.iloc[val_end_idx:]

    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "="*60)
    print("æ•°æ®åˆ†å‰²ç»Ÿè®¡:")
    print("="*60)

    for name, subset in [("è®­ç»ƒé›†", train_df), ("éªŒè¯é›†", val_df), ("æµ‹è¯•é›†", test_df)]:
        print(f"\n{name}:")
        print(f"  æ ·æœ¬æ•°: {len(subset):,} ({len(subset)/total_samples*100:.2f}%)")
        print(f"  æ—¶é—´èŒƒå›´: {subset.index[0]} è‡³ {subset.index[-1]}")

        # æ ‡ç­¾åˆ†å¸ƒ
        if 'label' in subset.columns:
            label_counts = subset['label'].value_counts().sort_index()
            print(f"  æ ‡ç­¾åˆ†å¸ƒ:")
            print(f"    SELL (0): {label_counts.get(0, 0):,} ({label_counts.get(0, 0)/len(subset)*100:.2f}%)")
            print(f"    HOLD (1): {label_counts.get(1, 0):,} ({label_counts.get(1, 0)/len(subset)*100:.2f}%)")
            print(f"    BUY  (2): {label_counts.get(2, 0):,} ({label_counts.get(2, 0)/len(subset)*100:.2f}%)")

    # ä¿å­˜åˆ†å‰²åçš„æ•°æ®
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    train_path = output_dir / 'train.csv'
    val_path = output_dir / 'val.csv'
    test_path = output_dir / 'test.csv'

    train_df.to_csv(train_path)
    val_df.to_csv(val_path)
    test_df.to_csv(test_path)

    print("\n" + "="*60)
    print("âœ… æ•°æ®åˆ†å‰²å®Œæˆï¼æ–‡ä»¶å·²ä¿å­˜è‡³:")
    print(f"  è®­ç»ƒé›†: {train_path} ({train_path.stat().st_size / 1024 / 1024:.2f} MB)")
    print(f"  éªŒè¯é›†: {val_path} ({val_path.stat().st_size / 1024 / 1024:.2f} MB)")
    print(f"  æµ‹è¯•é›†: {test_path} ({test_path.stat().st_size / 1024 / 1024:.2f} MB)")
    print("="*60)

    return train_df, val_df, test_df


def verify_no_data_leakage(train_df, val_df, test_df):
    """éªŒè¯æ•°æ®åˆ†å‰²æ²¡æœ‰æ—¶é—´æ³„æ¼"""
    train_end = train_df.index[-1]
    val_start = val_df.index[0]
    val_end = val_df.index[-1]
    test_start = test_df.index[0]

    assert train_end < val_start, "è®­ç»ƒé›†ä¸éªŒè¯é›†å­˜åœ¨æ—¶é—´é‡å ï¼"
    assert val_end < test_start, "éªŒè¯é›†ä¸æµ‹è¯•é›†å­˜åœ¨æ—¶é—´é‡å ï¼"

    print("\nâœ… æ•°æ®åˆ†å‰²éªŒè¯é€šè¿‡ï¼šæ— æ—¶é—´æ³„æ¼")
    print(f"  è®­ç»ƒé›†ç»“æŸ: {train_end}")
    print(f"  éªŒè¯é›†å¼€å§‹: {val_start}")
    print(f"  éªŒè¯é›†ç»“æŸ: {val_end}")
    print(f"  æµ‹è¯•é›†å¼€å§‹: {test_start}")


if __name__ == '__main__':
    import sys

    # é»˜è®¤å‚æ•°
    input_file = 'data/btc_usdt_1m_processed.csv'

    # æ”¯æŒå‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        input_file = sys.argv[1]

    # æ‰§è¡Œåˆ†å‰²
    train_df, val_df, test_df = split_time_series_data(
        input_file=input_file,
        output_dir='data',
        train_ratio=0.70,
        val_ratio=0.15,
        test_ratio=0.15
    )

    # éªŒè¯æ— æ—¶é—´æ³„æ¼
    verify_no_data_leakage(train_df, val_df, test_df)

    print("\nğŸ‰ æ•°æ®å‡†å¤‡å®Œæˆï¼ç°åœ¨å¯ä»¥è¿›è¡ŒEDAæˆ–æ¨¡å‹è®­ç»ƒäº†")
